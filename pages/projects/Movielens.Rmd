---
title: "MovieLens"
author: "Alan"
date: "September 2, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
load("~/MovieLens/test.RData")
library(tidyverse)
library(caret)
library(lubridate)
library(RColorBrewer)
library(gridExtra)
library(Matrix)
library(irlba)
library(ggthemes)
library(knitr)
#Add RMSE function
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

## Summary

The MovieLens data set contains the ratings that each user gave to watched movies. 
We used the 10M data set, divided into a training set called edx (made of 9,000,055 observations) and a validation set (999,999 observations) where we predicted the ratings.
After exploration of the data the edx set was divided into a train set and a valid set in order to find the model and tune the parameters, leading to the following model:
$Y_{u,i} = \mu + b_i + b_u + b_{y,i} + b_{y,u} + p_u q_i  + \varepsilon_{u,i}$ 
where it takes the average of the ratings, adds the regularized per movie effect, per user effect, year of movie released effect, year the user rated effect and using Single Value Decomposition to find 50 latent features.
This model help us achieve an RMSE of 0.8578388 on the validation set.

## Data Exploration
Before going to the model we need to understand the data and see the relations of the variables.
We see the structure of the data frame, the summary of the columns and how many unique users and movies are.

```{r Strut, echo=FALSE}
#See structure of data, summary and see distinct 
str(edx)
kable(summary(edx))
kable(edx %>% summarize(n_users = n_distinct(userId), n_movies = n_distinct(movieId)))
```

Our data is in 6 columns. The first 2 representing the user and movie id, then the variable that we need to predict, the time stamp is in value instead of a date format, and finally we have the title and genres.
We also see that we have more unique users than movies about 6 times more. 
Looking at the variable to predict, the lowest rating is .5, but the 1st quarterly is 3 so it seems that the ratings are high. Looking at a graph of ratings we see that we were right.

```{r rat , echo = FALSE}
edx$timestamp <- as_datetime(edx$timestamp)
edx %>% group_by(rating) %>% summarize(n = n()) %>%
  ggplot(aes(rating, sqrt(n))) + geom_col()
```
We took the sqrt of the counts to see the results better and we found the following. 
Whole ratings are more prevalent than half ratings.
Most of the ratings fall on 3 or 4, giving the set an average of 3.512.

Plotting the distribution of movies and users to see how many users rated a movie and how often the users rate, we get the following plots:
```{r distri}
p1 <- edx %>% count(movieId) %>% 
  ggplot(aes(n)) + geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + ggtitle("Movies")
p2 <- edx %>% count(userId) %>% 
  ggplot(aes(n)) + geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + ggtitle("Users")
grid.arrange(p1, p2, nrow = 1)
```

We see movies with only 1 rating, but overall looks like a normal distribution with most movies having around 100 ratings.
In the users we see that is right skewed, on average people rate low, with some users having rated 10 times.But there are other users that have rated more than 1000 times,

We plot the top 20 movies by number of ratings, and we find that there are big know movies like pulp fiction, Forrest gump, etc. The top 20 movies have over 20,000 ratings.


```{r movies, echo=FALSE}
rm(p1,p2) #removing extra data to conservate memory
edx %>% count(title, sort = TRUE) %>% head(20) %>% mutate(title = reorder(title, n)) %>%
  ggplot(aes(x = title, y = n, fill = title)) + geom_col(show.legend = FALSE) +
  coord_flip() +
  theme_minimal()
```

Plotting the top 20 users, we see that the first two have over 5,000 rated movies and the number of ratings decreases more quickly in comparison to the movies.

```{r users, echo=FALSE}
edx %>% count(userId, sort = TRUE) %>% head(20) %>% mutate(User = reorder(userId, n)) %>%
  ggplot(aes(x = User, y = n, fill = User)) + geom_col(show.legend = FALSE) +
  coord_flip()
```

### Movie Years effect on rating
We see that the titles have the year released next to them. We are interested to see if there is an influence of year released to ratings. 
In order to do so we will create a title data frame and extract the year from the title using the following code:

```{r titles manip}
titles <- edx %>% group_by(movieId, title) %>%
  select(movieId, title, genres, rating)
titles$Year <- str_extract(titles$title, "\\((\\d{4})\\)")
titles$Year <- str_remove(titles$Year,"\\(")
titles$Year <- str_remove(titles$Year,"\\)")
kable(titles[1:2,1:5])
```

Then we plot the average rating against the year and we find the following graph.

```{r moveyear, echo=FALSE}
# Year movie effects plot
titles$Year <- as.Date(titles$Year, format = '%Y')
titles %>% group_by(Year) %>% summarize(rating = mean(rating), n = n()) %>%
  ggplot(aes(Year,rating, size = n)) +
  geom_point(show.legend = FALSE) + geom_smooth(show.legend = FALSE) +
  theme(axis.text.x = element_text(angle = 90))
```
The size of the points represents the number of ratings. We see that recent movies have more ratings than older movies, however we see a trend. From 1980 the average rating starts to decrease.

### User year effect
Likewise we want to see if there is an effect from the date the user rated. 

```{r usereffect, echo=FALSE}
rm(titles)
#user effects plot
users <- edx[ ,!(names(edx) %in% c("genres", "title"))]
users$Year <- year(users$timestamp)
users %>% group_by(Year) %>%
  summarize(rating = mean(rating), n = n()) %>%
  ggplot(aes(Year,rating, size = sqrt(n))) +
  geom_point()
```
We see that except for the 1995 year, the rest of the years it goes up or down around the 3.5 of the mean.

## Choosing Parameters 
We are going to take those two effects and along the movie and users effects we are going to apply regularization.
In order to find the optimal lambda and the number of features for SVD we are going to divide the edx set into a train and valid set.

```{r splitinto, echo=FALSE}
rm(users)
###### We make train and valid sets with the following code, and save them as csv.

#Spliting EDX into training and valid sets for model creation
#set.seed(2019, sample.kind="Rounding")
#val_index <- createDataPartition(y = edx$rating, times = 1, p = 0.2, list = FALSE)
#train_set <- edx[-val_index,]
#temp <- edx[val_index,]
# Make sure userId and movieId are also in train set
#valid_set <- temp %>% 
#  semi_join(train_set, by = "movieId") %>%
#  semi_join(train_set, by = "userId")
# Add rows removed from valid set back into train set
#removed <- anti_join(temp, valid_set)
#train_set <- rbind(train_set, removed)
#rm(edx, removed, temp, val_index)
#write_csv2(train_set, "train_set")
#write_csv2(valid_set, "valid_set")

#reading the csv for train and valid sets
train_set <- read.csv2("~/MovieLens/train_set", stringsAsFactors=FALSE)
valid_set <- read.csv2("~/MovieLens/valid_set", stringsAsFactors=FALSE)
#modifying train and valid set ym is the title year and yu is the year of user
train_set$ym <- str_extract(train_set$title, "\\((\\d{4})\\)")
train_set$ym <- str_remove(train_set$ym,"\\(")
train_set$ym <- str_remove(train_set$ym,"\\)")
train_set$timestamp <- as_datetime(train_set$timestamp)
train_set$yeus <- year(train_set$timestamp)
valid_set$timestamp <- as_datetime(valid_set$timestamp)
valid_set$yeus <- year(valid_set$timestamp)
valid_set$ym <- str_extract(valid_set$title, "\\((\\d{4})\\)")
valid_set$ym <- str_remove(valid_set$ym,"\\(")
valid_set$ym <- str_remove(valid_set$ym,"\\)")
mu <- mean(train_set$rating)
```


```{r see struct}
kable(train_set[1:3,1:8])
```

With ym representing the year of the movie and yeus representing the year the user rated.
The train set has 7,200,083 of observations and the valid has 1,799,972 of observations.

### Regularization

There are users, years and movies with a small number of ratings that could bias the predicted rating, so we need to add a penalty to those small values using regularization. We need to find the lambda that minimizes the RMSE, first we take the values on the train set and use them to predict the values of the valid set, the one that minimizes the RMSE will be that lambda.
```{r lamda}
# Regularization, findind optimal lambda given:
lambdas <- seq(0, 10, 0.25)
rmses <- sapply(lambdas, function(l){
# movie mean
  mu <- mean(train_set$rating)
# movie effects  
  b_i <- train_set %>% 
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
# user effects  
  b_u <- train_set %>% 
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
# year of title effects
  b_y <- train_set %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    group_by(ym) %>%
    summarize(b_y = sum(rating - b_i - b_u - mu)/(n()+l))
# year user effects  
  b_yu <- train_set %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_y, by = "ym") %>%
    group_by(yeus) %>%
    summarize(b_yu = sum(rating - b_i - b_u - b_y - mu)/(n()+l))
  
  predicted_ratings <- 
    valid_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    left_join(b_y, by = "ym") %>%
    left_join(b_yu, by = "yeus") %>%
    mutate(pred = mu + b_i + b_u + b_y + b_yu) %>%
    pull(pred)
  
  return(RMSE(predicted_ratings, valid_set$rating))
})
qplot(lambdas, rmses)
```

```{r lam, echo=FALSE}
lambda <- lambdas[which.min(rmses)]
```

### SVD
We are going to optimize the number of latent features by minimizing the RMSE using the irlba library.
By using matrix factorization in this case SVD we can find latent features (wherever a movie is a blockbuster or niche, or the user preferences).
First we need to change our data frame to a matrix, rows for users and columns for movies. The resulting matrix will have points without values, that means the user has not rated that movie.

```{r matrix}
# changing from data frame to sparse matrix using matrix library
x <- train_set[ , c("userId","movieId","rating")]
x$rating <- x$rating - mu   #removing the mean as it will be added later in the final model
mat <- sparseMatrix(i = x$userId,j = x$movieId, x = x$rating)
```

```{r remove, include=FALSE}
#keep memory in check
rm(x, lambdas, rmses)
gc()
```

The irlba library calculates a truncated svd where you can select the number of singular values as long as is lower than the number of columns or rows. It also calculates when you have sparse matrix.
We are going to calculate different number and find the one with the lowest rmse.

```{r svd}
#  Finding the optimal number of svd 
SVD_5=irlba(mat,nu=5,nv=5)
SVD_50=irlba(mat,nu=50,nv=50)
SVD_75=irlba(mat,nu=75,nv=75)
SVD_100=irlba(mat,nu=100,nv=100)
plot(SVD_5$d, main="Largest singular values (r=5)") #see latent factors
```

```{r, include=FALSE}
rm(mat) #keep memory in check
gc() 
```

We are going to take the decomposition and dot multiply to have the predicted ratings.

```{r decomp}
# You need to separate and predict only on the values that you need, if you 
# dot product on the entire matix you will get a memory error
u_sigma5 <- SVD_5$u %*% diag(SVD_5$d)
vt5 <- t(SVD_5$v)
u_sigma50 <- SVD_50$u %*% diag(SVD_50$d)
vt50 <- t(SVD_50$v)
u_sigma75 <- SVD_75$u %*% diag(SVD_75$d)
vt75 <- t(SVD_75$v)
u_sigma100 <- SVD_100$u %*% diag(SVD_100$d)
vt100 <- t(SVD_100$v)
```

```{r, include=FALSE}
rm(SVD_5,SVD_50,SVD_100,SVD_75)
gc()
```

We cannot dot multiply the entire matrix because of memory limitations, so for each value we want to predict we take the dot product just of those values, in the following way.

```{r predsvd}
#testing on valid set
v <- valid_set[ ,c(1,2)]
id <- seq(1,length(valid_set[,1]),1)
# for 5 latent
calc <- function(i){
  user <- v[i,1]
  movie <- v[i,2]
  pred <- u_sigma5[user, ] %*% vt5[ ,movie]
} 
o5 <- lapply(id,calc)
df5 <- data.frame(matrix(unlist(o5), nrow=length(o5), byrow=T))
df5$rat <- df5$matrix.unlist.o5...nrow...length.o5...byrow...T. + mu
rm(o5,u_sigma5,vt5)
```


```{r predallsvd, echo=FALSE}
#for 50 latent
calc <- function(i){
  user <- v[i,1]
  movie <- v[i,2]
  pred <- u_sigma50[user, ] %*% vt50[ ,movie]
} 
o50 <- lapply(id,calc)
df50 <- data.frame(matrix(unlist(o50), nrow=length(o50), byrow=T))
df50$rat <- df50$matrix.unlist.o50...nrow...length.o50...byrow...T. + mu
rm(o50,u_sigma50,vt50)
#for 75 latent
calc <- function(i){
  user <- v[i,1]
  movie <- v[i,2]
  pred <- u_sigma75[user, ] %*% vt75[ ,movie]
} 
o75 <- lapply(id,calc)
df75 <- data.frame(matrix(unlist(o75), nrow=length(o75), byrow=T))
df75$rat <- df75$matrix.unlist.o75...nrow...length.o75...byrow...T. + mu
rm(o75,u_sigma75,vt75)
#for 100 latent
calc <- function(i){
  user <- v[i,1]
  movie <- v[i,2]
  pred <- u_sigma100[user, ] %*% vt100[ ,movie]
} 
o100 <- lapply(id,calc)
df100 <- data.frame(matrix(unlist(o100), nrow=length(o100), byrow=T))
df100$rat <- df100$matrix.unlist.o100...nrow...length.o100...byrow...T. + mu
rm(o100,u_sigma100,vt100)
```
```{r, include=FALSE}
gc()
```

We calculate the RMSE and we have the following

```{r rmsecals}
#calculate rmse
rmse5 <- RMSE(valid_set$rating,df5$rat)
rmse50 <- RMSE(valid_set$rating,df50$rat)
rmse75 <- RMSE(valid_set$rating,df75$rat)
rmse100 <- RMSE(valid_set$rating,df100$rat)
rm(df5,df50,df100,df75)
kable(RMSEpreds <- data.frame('r'=c(5,50,75,100),'RMSE'=c(rmse5,rmse50,rmse75 ,rmse100)))
```

The number of SVD will be 50.

```{r svdplot}
ggplot(RMSEpreds,aes(r,RMSE))+
  geom_line(col='blue',size=1) +
  geom_point(col='blue',size=2) +
  labs(x="Number of Singular Values", y="RMSE")
```

```{r, include=FALSE}
rm(rmse5,rmse50,rmse75 ,rmse100, id, v, RMSEpreds)
gc()
```

## Results
Taking all and using it to predict the valid rating we have.
```{r resltrain, echo=FALSE}
b_i <- train_set %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

b_y <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  group_by(ym) %>%
  summarize(b_y = sum(rating - b_i - b_u - mu)/(n()+lambda))

b_yu <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_y, by = "ym") %>%
  group_by(yeus) %>%
  summarize(b_yu = sum(rating - b_i - b_u - b_y - mu)/(n()+lambda))

x <- train_set[ , c("userId","movieId","rating")]
x$rating <- x$rating - mu
rm(train_set)
mat <- sparseMatrix(i = x$userId,j = x$movieId, x = x$rating)
rm(x)
SVD_50=irlba(mat,nu=50,nv=50) #better
rm(mat)
u_sigma <- SVD_50$u %*% diag(SVD_50$d)
vt <- t(SVD_50$v)
rm(SVD_50)

predicted_ratings <- 
  valid_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_y, by = "ym") %>%
  left_join(b_yu, by = "yeus")

v <- valid_set[ ,c(1,2)]
id <- seq(1,length(valid_set[,1]),1)

calc <- function(i){
  user <- v[i,1]
  movie <- v[i,2]
  pred <- u_sigma[user, ] %*% vt[ ,movie]
}
o <- lapply(id,calc)
df <- data.frame(matrix(unlist(o), nrow=length(o), byrow=T))
rm(o,u_sigma,v,vt,id,calc)

predicted_ratings$svd <- df$matrix.unlist.o...nrow...length.o...byrow...T.

predsmu <- predicted_ratings %>%
  mutate(pred = mu) %>%
  pull(pred)

preds1 <- predicted_ratings %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)
       
preds <- predicted_ratings %>%
  mutate(pred = mu + b_i + b_u + b_y + b_yu + svd) %>%
  pull(pred)

res <- RMSE(valid_set$rating,preds)
res1 <- RMSE(valid_set$rating,preds1)
resmu <- RMSE(valid_set$rating,predsmu)

kable(Comp <- data.frame('Model'=c("Average","Movie and User", "New"),'RMSE'=c(resmu,res1,res)))
```

```{r, include=FALSE}
rm(b_i,b_u,b_y,b_yu,Comp,df,predicted_ratings,valid_set,preds,preds1,predsmu,res,res1,resmu)
gc()
```
We see that the results improve as we add more effects and latent features, however using this approach, looks that improving becomes difficult as with all the effects added we just improve 0.01. So other methods are needed in order to improve even more.

We use this approach to the whole set in order to predict the ratings in the validation set and we obtain the following result.
```{r, echo=FALSE}
edx$ym <- str_extract(edx$title, "\\((\\d{4})\\)")
edx$ym <- str_remove(edx$ym,"\\(")
edx$ym <- str_remove(edx$ym,"\\)")
edx$timestamp <- as_datetime(edx$timestamp)
edx$yeus <- year(edx$timestamp)
validation$timestamp <- as_datetime(validation$timestamp)
validation$yeus <- year(validation$timestamp)
validation$ym <- str_extract(validation$title, "\\((\\d{4})\\)")
validation$ym <- str_remove(validation$ym,"\\(")
validation$ym <- str_remove(validation$ym,"\\)")
mu <- mean(edx$rating)
lambda <- 5

b_i <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

b_y <- edx %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  group_by(ym) %>%
  summarize(b_y = sum(rating - b_i - b_u - mu)/(n()+lambda))

b_yu <- edx %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_y, by = "ym") %>%
  group_by(yeus) %>%
  summarize(b_yu = sum(rating - b_i - b_u - b_y - mu)/(n()+lambda))

x <- edx[ , c("userId","movieId","rating")]
x$rating <- x$rating - mu
rm(edx)
mat <- sparseMatrix(i = x$userId,j = x$movieId, x = x$rating)
rm(x)
SVD_50=irlba(mat,nu=50,nv=50) #better
rm(mat)
u_sigma <- SVD_50$u %*% diag(SVD_50$d)
vt <- t(SVD_50$v)
rm(SVD_50)

predicted_ratings <- 
  validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(b_y, by = "ym") %>%
  left_join(b_yu, by = "yeus")

v <- validation[ ,c(1,2)]
id <- seq(1,length(validation[,1]),1)

calc <- function(i){
  user <- v[i,1]
  movie <- v[i,2]
  pred <- u_sigma[user, ] %*% vt[ ,movie]
}
o <- lapply(id,calc)
df <- data.frame(matrix(unlist(o), nrow=length(o), byrow=T))
rm(o,u_sigma,v,vt,id,calc)

predicted_ratings$svd <- df$matrix.unlist.o...nrow...length.o...byrow...T.

preds <- predicted_ratings %>%
  mutate(pred = mu + b_i + b_u + b_y + b_yu + svd) %>%
  pull(pred)

kable(RMSE(validation$rating,preds))
```
```{r, include=FALSE}
rm(b_i,b_u,b_y,b_yu,df,predicted_ratings,validation,preds)
gc()
```

We see that it is a little bit worse, but still manages to be in the .85 part.

## Conclusion
SVD is the one that helps more in the improvements rather than the year effects. When doing this we found other alternatives like collaborative filtering using neural nets, so in the future we are going to explore that and see the improvement.
Nevertheless this is a good model that manages to lower the RMSE and help us to learn even more, especially memory management and how to deal with large data sets.
